<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project: Web Scraper</title>
    <link rel="stylesheet" type="text/css" href="../styles.css">
    <link rel="icon" href="../images/favicon.ico">
</head>

<body>
    <section class="header">
        <div class="header-inner">
            <nav>
                <ul>
                    <li><a href="/">Home</a></li>
                    <li><a href="/all-projects">All Projects</a></li>
                </ul>
            </nav>
            <div class="header-contact">
                <a href="/resume.pdf" target="_blank">Resume</a>
                <a href="https://www.linkedin.com/in/benjamin-schoolland-907455254/" target="_blank">LinkedIn</a>
                <a href="https://github.com/BSchoolland" target="_blank">GitHub</a>
            </div>
        </div>
    </section>
    <section class="intro">
        <div class="intro-inner">
            <!-- to be populated by JavaScript -->
        </div>
    </section>
    <section class="content">
        <div class="content-inner">
            <h2>Web Scraping Project at Digital NEST</h2>
            <p>At Digital NEST, I was part of an intern group developing a web scraping
                application aimed at aggregating job listings from various sites like Indeed and LinkedIn. This tool is
                designed to help interns and Digital NEST members find potential career opportunities.</p>

            <h3>Project Contributions</h3>
            <p>Leading Backend Development: Because I already have some experience in backend development, I've written
                most of the code for the scraping process and mentored team members new to this area. It's rewarding to
                see my peers, primarily frontend developers, expand their backend skills.</p>

            <p>So far, our team has:</p>
            <ul>
                <li>Developed a visually appealing frontend using React.js.</li>
                <li>Integrated it with a backend server on Node.js.</li>
                <li>Implemented a temporary "database" with Google Sheets, offering a no-code setup for configuring our
                    scraper and viewing data.</li>
                <li>Built robust web scrapers using Puppeteer and Cheerio that navigate sitemaps and extract data
                    effectively.</li>
            </ul>

            <h3>Key Learnings</h3>
            <ul>
            <li>Handling messy data: The process of parsing raw HTML into useful data has been a very unique coding
                experience, and has taught me the value of good error handling.</li>
            <li>Reusability and Maintainability: My first attempt at web scraping worked, but it was inflexible. After
                rewriting it as a reusable class that accepts a JSON sitemap, it became much easier to work with and
                configure to work on a variety of sites. This has only reaffirmed the idea that when forced to choose
                between making something quickly or making something maintainable, I should always focus on
                maintainability.</li>
            <li>Scraping Ethically: If done carelessly, web scraping can be damaging to websites or violate their rules.
                As such, our team has made sure to get permission as well as making sure our code doesn’t make too many
                requests in a short period of time.</li>
            </ul>
            <p>I'm looking forward to refining this tool, and I hope it will be impactful for the interns and members
                here at the NEST!</p>
            <p>I am also excited to see what else I can do with puppeteer. After working (somewhat painfully) with raw
                and changing HTML data, I have a theory that using the ChatGPT API in combination with our configurable
                web scraper tool could prove very useful…</p>

            <p>I can't show the full project code as it is an internal tool and not open source, but I am able to share part of the code I wrote for the project, namely a powerful and reusable web scraper class: </p>

        </div>
    </section>
    <section class="links">
        <div class="links-inner">
            <!-- for project specific links (populated by JavaScript) -->
        </div>
    </section>
    <br />
    <br />
    <section class="footer">
        <div class="footer-inner">
            <p>Benjamin Schoolland</p>
        </div>
    </section>
    <div id="loading-screen"
        style="position: fixed; left: 0; top: 0; width: 100%; height: 100%; background-color: rgba(0,0,0,1); display: flex; justify-content: center; align-items: center; z-index: 1000;">
        <p>Loading...</p>
    </div>
    <script src="./pages.js"></script>

</body>

</html>